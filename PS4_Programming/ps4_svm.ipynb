{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "We’ve attached a dataset, $\\texttt{MNISTdata.mat}$, containing a sample of the famout MNISTbenchmark (http://yann.lecun/com/exdb/mnist).   Your  report  must  provide  summaries  of  each  method’s  performance  andsome  additional  details  of  your  implementation.   Compare  the  relative  strengths  andweaknesses of the methods based on both the experimental results and your understandingof the algorithms. \n",
    "\n",
    "You can load the data with $\\texttt{scipy.io.loadmat}$, which will return a Python dictionarycontaining the test and train data and labels.\n",
    "\n",
    "The purpose of this assignment is for you to implement the SVM. You are not allowed toimport an SVM from, for instance, $\\texttt{scikit-learn}$.  You may, however, use a library (suchas $\\texttt{scipy.optimize.minimize}$ or $\\texttt{cvxopt.solvers.qp}$) for the optimization process.\n",
    "\n",
    "Please refer to the instructions in the PDF document coming with the writen problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) SVM for binary classifications\n",
    "\n",
    "Develop code for training an SVM for binary classification with nonlinear kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sci\n",
    "import numpy as np\n",
    "from cvxopt import solvers\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from math import e\n",
    "f = sci.loadmat(\"MNIST_data.mat\")\n",
    "train_sample = f['train_samples']\n",
    "train_label = f['train_samples_labels']\n",
    "test_sample = f['test_samples']\n",
    "test_label = f['test_samples_labels']\n",
    "train_data = np.hstack([train_sample,train_label])\n",
    "\n",
    "\n",
    "def svm(data,num1, num2):\n",
    "    Y = data[:,-1]\n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i] == num1:\n",
    "            Y[i] = 1\n",
    "        else:\n",
    "            Y[i] = -1\n",
    "\n",
    "    X = data[:,:-1]\n",
    "    n,m = X.shape\n",
    "    K = np.matmul(X,X.transpose())\n",
    "    K = K + 2\n",
    "    K = np.square(K)\n",
    "    \n",
    "    T = np.diag(Y)\n",
    "    P = cvxopt_matrix(np.matmul(np.matmul(T,K),T))\n",
    "    q = cvxopt_matrix(-np.ones((n)))\n",
    "    G = cvxopt_matrix(-np.eye(n))\n",
    "    h = cvxopt_matrix(np.zeros(n))\n",
    "    b = cvxopt_matrix(np.zeros(1))\n",
    "    A = cvxopt_matrix(np.asmatrix(Y))\n",
    "    solvers.options['show_progress'] = False\n",
    "    alpha = np.array(solvers.qp(P,q,G,h,A,b)['x'])\n",
    "    w = sum([alpha[i]*Y[i]*X[i,:] for i in range(n)])\n",
    "    b = 1/n*(sum([Y[i]-np.dot(w,X[i,:]) for i in range(n)]))\n",
    "    return w,b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Predict for new data\n",
    "\n",
    "Develop code for predict the $\\{-1, +1\\}$ for new data. To use the predictive model (7.13) you need to determine $b$, which can be done with (7.37)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_sample, test_sample,num1,num2):\n",
    "    w,b = svm(train_sample,num1,num2)\n",
    "    print(b)\n",
    "    result = []\n",
    "    for i in range(test_sample.shape[0]):\n",
    "        result.append(np.sign(np.dot(w,test_sample[i,:])+b))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Multiclass classification\n",
    "\n",
    "Useing your implementation, compare multiclass classification performance of two different voting schemes: \n",
    " i. one versus rest;\n",
    " ii. one versus one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = [] \n",
    "for i in range(10):\n",
    "    f = sci.loadmat(\"MNIST_data.mat\")\n",
    "    train_sample = f['train_samples']\n",
    "    train_label = f['train_samples_labels']\n",
    "    test_sample = f['test_samples']\n",
    "    test_label = f['test_samples_labels']\n",
    "    train_data = np.hstack([train_sample,train_label])\n",
    "    w,b = svm(train_data,i,num2 = None)\n",
    "    final_result += [np.append(w,b)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for i in test_sample:\n",
    "    lst = []\n",
    "    count = 0\n",
    "    for j in final_result:\n",
    "        lst += [[np.matmul(i.transpose(),j[:-1])+j[-1],count]]\n",
    "        \n",
    "        count += 1\n",
    "    result += [max(lst)[1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.772\n",
      "[[ 84   0   6   2   1  16   4   1   7   1]\n",
      " [  0 118   7   2   0   3   1   1   2   1]\n",
      " [  0   0  78   1   0   2   2   0   1   0]\n",
      " [  0   0   7  86   0   6   0   2   3   4]\n",
      " [  0   0   0   3  98   9   0   1   8  18]\n",
      " [  0   0   0   6   0  44   2   0   1   0]\n",
      " [  1   1   3   6   2   1  76   0   2   0]\n",
      " [  0   0   5   7   3   6   2  86   5  19]\n",
      " [  0   3   5   0   1   2   0   0  54   1]\n",
      " [  1   0   2   2   3   3   0   8   3  48]]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(result)):\n",
    "    if result[i] == test_label[i]:\n",
    "        count += 1 \n",
    "print(count/len(result))\n",
    "confusion_matrix =np.diag([0]*10)\n",
    "for i in range(len(result)):\n",
    "    confusion_matrix[int(result[i]),int(test_label[i,0])] += 1\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one vs one\n",
    "\n",
    "model_set = []\n",
    "for i in range(10):\n",
    "    for k in range(0,10):\n",
    "        if k != i:\n",
    "            pos_sample = []\n",
    "            pos_label = []\n",
    "            for j in range(len(train_label)):\n",
    "                if train_label[j] == i or train_label[j] == k:\n",
    "                    pos_sample.append(train_sample[j])\n",
    "                    pos_label.append(train_label[j])\n",
    "            model_set += [[svm(np.hstack([np.array(pos_sample),np.array(pos_label)]),i,k),i,k]]\n",
    "    \n",
    "predict = []\n",
    "for i in range(test_label.shape[0]):\n",
    "    lst = {}\n",
    "    for j in range(90):\n",
    "        w,b = model_set[j][0]\n",
    "        if np.dot(w,test_sample[i]) + b > 0:\n",
    "            if model_set[j][1] not in lst:\n",
    "                lst[model_set[j][1]] = 1\n",
    "            else:\n",
    "                lst[model_set[j][1]] += 1\n",
    "    \n",
    "            \n",
    "    predict += [max(lst, key=lst.get)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9\n",
      "[[ 84   0   0   0   0   1   3   0   1   0]\n",
      " [  0 122   5   3   0   2   0   1   3   2]\n",
      " [  1   0  96   1   0   0   1   3   0   0]\n",
      " [  0   0   0  98   0   5   0   1   4   0]\n",
      " [  0   0   1   0 101   2   0   2   4   3]\n",
      " [  0   0   0   5   0  77   1   0   0   0]\n",
      " [  1   0   1   1   2   1  82   0   0   0]\n",
      " [  0   0   3   4   0   0   0  89   3   2]\n",
      " [  0   0   4   2   0   4   0   0  67   1]\n",
      " [  0   0   3   1   5   0   0   3   4  84]]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(predict)):\n",
    "    if predict[i] == test_label[i]:\n",
    "        count += 1 \n",
    "print(count/len(predict))\n",
    "confusion_matrix =np.diag([0]*10)\n",
    "for i in range(len(predict)):\n",
    "    confusion_matrix[int(predict[i]),int(test_label[i,0])] += 1\n",
    "print(confusion_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my implement, one-vs-one is strictly much faster than one-vs-rest method and even more accurate. The reason that one-vs-one is faster than one-vs-rest maybe because one-vs-rest's quadratic problem cost much more time as size of data is larger.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Hyperparameter\n",
    "\n",
    "The parameter $C >0$ controls the tradeoff between the size of the margin and theslack variable penalty.  It is analogous to the inverse of a regularization coefficient.Include in your report a brief discussion of how you found an appropriate value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As C is closer to inf, the more overfit hyperplane is. the opposite otherwise. In order to find an appropriate value for C, we can form a integer loop from 0 to 1000 and inf and generate optimal solution each time and check accuracy rate of how the optimal solution alpha perform in the binary classification and finally choose one integer that perform the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (e) Confusion matrix\n",
    "\n",
    "In addition to calculating percent accuracy, generate multiclass confusion matrices (https://en.wikipedia.org/wiki/Confusionmatrix) as part of your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
