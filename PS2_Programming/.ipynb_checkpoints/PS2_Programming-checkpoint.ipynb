{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 542 Machine Learning, Summer 2020, PS2 Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming\n",
    "\n",
    "### (a) Linear Regression \n",
    "\n",
    "We are given data used in a study of the homicide rate (HOM) in Detroit, over the years 1961-1973. The following data were collected by J.C. Fisher, and used in his paper ”Homicide in Detroit: The Role of Firearms,” Criminology, vol. 14, pp. 387-400, 1976. Each row is for a year, and each column are values of a variable.\n",
    "\n",
    "![](table.png)\n",
    "\n",
    "It turns out that three of the variables together are good predictors of the homicide rate: `FTP`, `WE`, and one more variable.\n",
    "Use methods described in Chapter 3 of the textbook to devise a mathematical formulation to determine the third variable. Implement your formulation and then conduct experiments to determine the third variable. In your report, be sure to provide the step-by-step mathematical formulation (citing Chapter 3 as needed) that corresponds to the implementation you turn in. Also give plots and a rigorous argument to justify the scheme you use and your conclusions.\n",
    "\n",
    "**Note**: the file `detroit.npy` containing the data is given on the resources section of our course Piazza. To load the data into Python, use `X=numpy.load(‘detroit.npy’)` command. Least-squares linear regression in Python can be done with the help of `numpy.linalg.lstsq()`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer:**\n",
    "\n",
    "Type your step-by-step mathematical formualtion (citing chapter 3 as needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As $y(x,w) = w_0 +w_1x_1 +w_2x_2 +w_3x_3 = \\sum^3_{i=0}w_i x_i$\\\n",
    "where $x_1, x_2,x_3$ are normalized,(min-max method $x_i = (x_{i}-x_{min})/(x_{max}-x_{min})$\\\n",
    "And $E(w) = 0.5 \\sum^N_{n=1}(t_n-w^T\\phi(x_n))^2$\\\n",
    "the w that results in least ss is $(\\Phi^T\\Phi)^{-1}\\Phi^Tt$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[205.68495535685787, 136.5068394358309, 45.73263296763183, 89.97348063348171, 55.10257826659985, 52.89030061979331, 212.70446475221664]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.load('detroit.npy')\n",
    "result = []\n",
    "for i in range(1,8):\n",
    "    newX = X[:,[0, i, 8]]\n",
    "    n,m = newX.shape\n",
    "    X0 = np.ones((n,1))\n",
    "    newX = np.column_stack((newX,X0))\n",
    "    x,residuals,rank,s = np.linalg.lstsq(newX,X[:,9],rcond=-1)\n",
    "    ss = 0\n",
    "    for i in range(n):\n",
    "        ss += (X[i,9] - x[0]*newX[i,0]-x[1]*newX[i,1]-x[2]*newX[i,2]-x[3]*newX[i,3])**2\n",
    "    result += [ss]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(['UEMP','MAN','LIC','GR','NMAN','GOV','HE'],result)\n",
    "plt.ylabel('ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we should choose LIC as it minimizes ss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) k-Nearest Neighbors\n",
    "\n",
    "For this problem, you will be implementing the k-Nearest Neighbor (k-NN) classifier and evaluating on the `Credit Approval` (CA) dataset. It describes credit worthiness data (in this case, binary classification). (see http://archive.ics.uci.edu/ml/datasets/Credit+Approval) We have split the available data into a training set `crx.data.training` and a testing set `crx.data.testing`. These are both comma-separated text files (CSVs). \n",
    "\n",
    "The first step to working with the CA dataset is to process the data. In looking at the data description `crx.names`, note that there are some missing values, there exist both numerical and categorical features, and that it is a relatively balanced dataset (meaning a roughly equal number of positive and negative examples - not that you should particularly care in this case, but something you should look for in general). A great Python library for handling data like this is Pandas (https://pandas.pydata.org/pandas-docs/stable/). You can read in the data with `X = pandas.read csv(‘crx.data.training’, header=None, na values=‘?’)`. The last option tells Pandas to treat the character `?` as a missing value. \n",
    "\n",
    "Pandas holds data in a \"dataframe\". We'll deal with individual rows and columns, which Pandas calls \"series\". Pandas contains many convenient tools, bu the most basic you'll use is `X.iloc[i,j]`, accessing the element in the i-th row and j-th column. You can use this for both getting and setting values. You can also slice like normal Python, grabbing the i-th row with `[i,:]`. \n",
    "\n",
    "You can view the first 20 rows with `X.head(20)`. The last column, number 15, contains the labels. You’ll see some elements are missing, marked with `NaN`. While there are more sophisticated (and better) methods for imputing missing values, for this assign- ment, we will just use mean/mode imputation. This means that for feature 0, you should replace all of the question marks with a `b` as this is the mode, the most common value (regardless if you condition on the label or not). For real-valued features, just replace missing values with the label-conditioned mean (e.g. $μ(x_1|+)$ for instances labeled as positive).\n",
    "\n",
    "The second aspect one should consider is normalizing features. Nominal features can be left in their given form where we define the distance to be a constant value (e.g. 1) if they are different values, and 0 if they are the same. However, it is often wise to normalize real-valued features. For the purpose of this assignment, we will use $z$-scaling, where\n",
    "\n",
    "$$z_{i}^{(m)} \\leftarrow \\frac{x_{i}^{(m)}-\\mu_{i}}{\\sigma_{i}}$$\n",
    "\n",
    "such that $z(m)$ indicates feature $i$ for instance $m$ (similarly $x(m)$ is the raw input), $μ_i$ is\n",
    "the average value of feature $i$ over all instances, and $σ_i$ is the corresponding standard deviation over all instances.\n",
    "\n",
    "In this notebook, include the following functions:\n",
    "\n",
    "i. A function `impute_missing_data()` that accepts two Pandas dataframes, one training and one testing, and returns two dataframes with missing values filled in. In your report include your exact methods for each type of feature. Note that you are free to impute the values using statistics over the entire dataset (training and testing combined) or just training, but please state your method.\n",
    "\n",
    "ii. A function normalize `features()` that accepts a training and testing dataframe and returns two dataframes with real-valued features normalized.\n",
    "\n",
    "iii. A function `distance()` that accepts two rows of a dataframe and returns a float, the L2 distance: $D_{L2}(\\mathbf{a},\\mathbf{b}) = \\sqrt{\\sum_i (ai −bi)^2}$ . Note that we define $D_{L2}$ to have a component-wise value of 1 for categorical attribute-values that disagree and 0 if they do agree (as previously implied). Remember not to use the label column in your distance calculation!\n",
    "\n",
    "iv. A funtion `predict()` that accepts three arguments: a training dataframe, a testing dataframe, and an integer $k$ - the number of nearest neighbors to use in predicting. This function should return a column of $+/-$ labels, one for every row in the testing data.\n",
    "\n",
    "v. A function `accuracy()` that accepts two columns, one true labels and one predicted by your algorithm, and returns a float between 0 and 1, the fraction of labels you guessed correctly.\n",
    "\n",
    "In your report, include accuracy results on `crx.data.testing` for at least three different values of `k`.\n",
    "\n",
    "vi. Try your algorithm on some other data! We’ve included the “lenses” dataset (https://archive.ics.uci.edu/ml/datasets/Lenses). It has no missing values and only categorical attributes, so no need for imputation or normalization. Include accuracy results from `lenses.testing` in your report as well. \n",
    "\n",
    "The code you submit must be your own. If you find/use information about specific algorithms from the Web, etc., be sure to cite the source(s) clearly in your sourcecode. You are not allowed to submit code downloaded from the internet (obviously).\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.603 5.842876984126985 3.200515873015873 4.412698412698413 164.6829268292683 2069.4841269841268\n",
      "0.8913043478260869\n",
      "0.8985507246376812\n",
      "0.9202898550724637\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "X = pd.read_csv('crx.data.training', header=None, na_values='?')\n",
    "Y = pd.read_csv('crx.data.testing', header=None, na_values='?')\n",
    "X,Y = impute_missing_data(X,Y)\n",
    "X,Y = features(X,Y)\n",
    "prediction1 = predict(X,Y,3)\n",
    "prediction2 = predict(X,Y,5)\n",
    "prediction3 = predict(X,Y,7)\n",
    "print(accuracy(prediction1,Y.iloc[:,15].tolist()))\n",
    "print(accuracy(prediction2,Y.iloc[:,15].tolist()))\n",
    "print(accuracy(prediction3,Y.iloc[:,15].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "0.8333333333333334\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "A = pd.read_csv('lenses.training', header=None, na_values='?')\n",
    "B = pd.read_csv('lenses.testing', header=None, na_values='?')\n",
    "p1 = predict(A,B,3)\n",
    "p2 = predict(A,B,5)\n",
    "p3 = predict(A,B,2)\n",
    "print(accuracy(p1,B.iloc[:,-1].tolist()))\n",
    "print(accuracy(p2,B.iloc[:,-1].tolist()))\n",
    "print(accuracy(p3,B.iloc[:,-1].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(colA,colB):\n",
    "    count = 0\n",
    "    for i in range(len(colA)):\n",
    "        if colA[i] == colB[i]:\n",
    "            count += 1\n",
    "    return count/len(colA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train,test,k):\n",
    "    dataset = pd.concat([train, test], ignore_index=True)\n",
    "    n,m = dataset.shape\n",
    "    x,y = test.shape\n",
    "    result = []\n",
    "    for i in range(x):\n",
    "        d = []\n",
    "        for j in range(n):\n",
    "            d.append([distance(test.iloc[i], dataset.iloc[j]),j])\n",
    "        d.sort()\n",
    "        d = d[:k]\n",
    "        dic = {}\n",
    "        for i in range(k):\n",
    "            if dataset.iloc[d[i][1],-1] not in dic:\n",
    "                dic[dataset.iloc[d[i][1],-1]] = 1\n",
    "            else:\n",
    "                dic[dataset.iloc[d[i][1],-1]] += 1\n",
    "        result.append(max(dic, key=dic.get))\n",
    "        \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(a,b):\n",
    "    s = 0\n",
    "    for i in range(len(a)-1):\n",
    "        if type(a[i]) == str:\n",
    "            if a[i] != b[i]:\n",
    "                s+=1\n",
    "        else:\n",
    "            s += (a[i]-b[i])**2\n",
    "    return math.sqrt(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(X,Y):\n",
    "    n,m=X.shape\n",
    "    for i in [1,2,7,10,13,14]:\n",
    "        mu = np.mean(X.iloc[:,i])\n",
    "        std = np.std(X.iloc[:,i])\n",
    "        for j in range(n):\n",
    "            X.iloc[j,i] = (X.iloc[j,i]-mu)/std\n",
    "    x,y=Y.shape\n",
    "    for i in [1,2,7,10,13,14]:\n",
    "        mu = np.mean(Y.iloc[:,i])\n",
    "        std = np.std(Y.iloc[:,i])\n",
    "        for j in range(x):\n",
    "            Y.iloc[j,i] = (Y.iloc[j,i]-mu)/std\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_data(X,Y):\n",
    "    n,m = X.shape\n",
    "    sum1 = [X.iloc[i,1] for i in range(n) if X.iloc[i,15] == \"+\" and str(X.iloc[i,1]) != \"nan\"]\n",
    "    mu1 = np.mean(sum1)\n",
    "    sum2=[X.iloc[i,2] for i in range(n) if X.iloc[i,15] == \"+\" and str(X.iloc[i,2]) != \"nan\"]\n",
    "    mu2= np.mean(sum2)\n",
    "    sum7 = [X.iloc[i,7] for i in range(n) if X.iloc[i,15] == \"+\" and str(X.iloc[i,7]) != \"nan\"]\n",
    "    mu7= np.mean(sum7)\n",
    "    sum10 = [X.iloc[i,10] for i in range(n) if X.iloc[i,15] == \"+\" and str(X.iloc[i,10]) != \"nan\"]\n",
    "    mu10= np.mean(sum10)\n",
    "    sum13 = [X.iloc[i,13] for i in range(n) if X.iloc[i,15] == \"+\" and str(X.iloc[i,13]) != \"nan\"]\n",
    "    mu13= np.mean(sum13)\n",
    "    sum14 = [X.iloc[i,14] for i in range(n) if X.iloc[i,15] == \"+\" and str(X.iloc[i,14]) != \"nan\"]\n",
    "    mu14= np.mean(sum14)\n",
    "    print(mu1,mu2,mu7,mu10,mu13,mu14)\n",
    "    for i in range(n):\n",
    "        if str(X.iloc[i,0]) == \"nan\":\n",
    "            X.iloc[i,0] = \"b\"\n",
    "        if str(X.iloc[i,1]) == \"nan\":\n",
    "            X.iloc[i,1] = mu1\n",
    "        if str(X.iloc[i,2]) == \"nan\":\n",
    "            X.iloc[i,2] = mu2\n",
    "        if str(X.iloc[i,3]) == \"nan\":\n",
    "            X.iloc[i,3] = \"u\"\n",
    "        if str(X.iloc[i,4]) == \"nan\":\n",
    "            X.iloc[i,4] = \"g\"\n",
    "        if str(X.iloc[i,5]) == \"nan\":\n",
    "            X.iloc[i,5] = \"c\"\n",
    "        if str(X.iloc[i,6]) == \"nan\":\n",
    "            X.iloc[i,6] = \"v\"\n",
    "        if str(X.iloc[i,7]) == \"nan\":\n",
    "            X.iloc[i,7] = mu7\n",
    "        if str(X.iloc[i,8]) == \"nan\":\n",
    "            X.iloc[i,8] = \"t\"\n",
    "        if str(X.iloc[i,9]) == \"nan\":\n",
    "            X.iloc[i,9] = \"f\"\n",
    "        if str(X.iloc[i,10]) == \"nan\":\n",
    "            X.iloc[i,10] = mu10\n",
    "        if str(X.iloc[i,11]) == \"nan\":\n",
    "            X.iloc[i,11] = \"f\"\n",
    "        if str(X.iloc[i,12]) == \"nan\":\n",
    "            X.iloc[i,12] = \"g\"\n",
    "        if str(X.iloc[i,13]) == \"nan\":\n",
    "            X.iloc[i,13] = mu13\n",
    "        if str(X.iloc[i,14]) == \"nan\":\n",
    "            X.iloc[i,14] = mu14\n",
    "    x,y = Y.shape\n",
    "    sum1 = [Y.iloc[i,1] for i in range(x) if Y.iloc[i,15] == \"+\" and str(Y.iloc[i,1]) != \"nan\"]\n",
    "    mu1 = sum(sum1)/len(sum1)\n",
    "    sum2=[Y.iloc[i,2] for i in range(x) if Y.iloc[i,15] == \"+\" and str(Y.iloc[i,2]) != \"nan\"]\n",
    "    mu2=sum(sum2)/len(sum2)\n",
    "    sum7 = [Y.iloc[i,7] for i in range(x) if Y.iloc[i,15] == \"+\" and str(Y.iloc[i,7]) != \"nan\"]\n",
    "    mu7=sum(sum7)/len(sum7)\n",
    "    sum10 = [Y.iloc[i,10] for i in range(x) if Y.iloc[i,15] == \"+\" and str(Y.iloc[i,10]) != \"nan\"]\n",
    "    mu10=sum(sum10)/len(sum10)\n",
    "    sum13 = [Y.iloc[i,13] for i in range(x) if Y.iloc[i,15] == \"+\" and str(Y.iloc[i,13]) != \"nan\"]\n",
    "    mu13=sum(sum13)/len(sum13)\n",
    "    sum14 = [Y.iloc[i,14] for i in range(x) if Y.iloc[i,15] == \"+\" and str(Y.iloc[i,14]) != \"nan\"]\n",
    "    mu14=sum(sum14)/len(sum14)\n",
    "    for i in range(x):\n",
    "        if str(Y.iloc[i,0]) == \"nan\":\n",
    "            Y.iloc[i,0] = \"b\"\n",
    "        if str(Y.iloc[i,1]) == \"nan\":\n",
    "            Y.iloc[i,1] = mu1\n",
    "        if str(Y.iloc[i,2]) == \"nan\":\n",
    "            Y.iloc[i,2] = mu2\n",
    "        if str(Y.iloc[i,3]) == \"nan\":\n",
    "            Y.iloc[i,3] = \"u\"\n",
    "        if str(Y.iloc[i,4]) == \"nan\":\n",
    "            Y.iloc[i,4] = \"g\"\n",
    "        if str(Y.iloc[i,5]) == \"nan\":\n",
    "            Y.iloc[i,5] = \"c\"\n",
    "        if str(Y.iloc[i,6]) == \"nan\":\n",
    "            Y.iloc[i,6] = \"v\"\n",
    "        if str(Y.iloc[i,7]) == \"nan\":\n",
    "            Y.iloc[i,7] = mu7\n",
    "        if str(Y.iloc[i,8]) == \"nan\":\n",
    "            Y.iloc[i,8] = \"t\"\n",
    "        if str(Y.iloc[i,9]) == \"nan\":\n",
    "            Y.iloc[i,9] = \"f\"\n",
    "        if str(Y.iloc[i,10]) == \"nan\":\n",
    "            Y.iloc[i,10] = mu10\n",
    "        if str(Y.iloc[i,11]) == \"nan\":\n",
    "            Y.iloc[i,11] = \"f\"\n",
    "        if str(Y.iloc[i,12]) == \"nan\":\n",
    "            Y.iloc[i,12] = \"g\"\n",
    "        if str(Y.iloc[i,13]) == \"nan\":\n",
    "            Y.iloc[i,13] = mu13\n",
    "        if str(Y.iloc[i,14]) == \"nan\":\n",
    "            Y.iloc[i,14] = mu14\n",
    "        \n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report:\\\n",
    "$\\text{Feature 0: replace all the nan with b}$\\\n",
    "$\\text{Feature 1: repalce all the nan with \\mu(x|+) = 33.603}$\\ \n",
    "$\\text{Feature 2: repalce all the nan with \\mu(x|+) = 5.84}$\\\n",
    "$\\text{Feature 3: replace all the nan with u}$\\\n",
    "$\\text{Feature 4: replace all the nan with g}$\\\n",
    "$\\text{Feature 5: replace all the nan with c}$\\\n",
    "$\\text{Feature 6: replace all the nan with v}$\\\n",
    "$\\text{Feature 7: repalce all the nan with \\mu(x|+) = 3.2}$\\\n",
    "$\\text{Feature 8: replace all the nan with t}$\\\n",
    "$\\text{Feature 9: replace all the nan with f}$\\\n",
    "$\\text{Feature 10: repalce all the nan with \\mu(x|+) = 4.41}$\\\n",
    "$\\text{Feature 11: replace all the nan with f}$\\\n",
    "$\\text{Feature 12: replace all the nan with g}$\\\n",
    "$\\text{Feature 13: repalce all the nan with \\mu(x|+) = 164.68}$\\\n",
    "$\\text{Feature 14: repalce all the nan with \\mu(x|+) = 2069.5}$\\\n",
    "$\\text{For crx.data.testing, I tried k = 3, where accuracy is 0.891, k = 5. where accuracy is 0.898, k = 7 where accuracy is 0.92.}$\\\n",
    "$\\text{For lenses.testing, I tried k = 2, where accuracy is 1, k = 3. where accuracy is 0.833, k = 5 where accuracy is 0.83.}$\\\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
